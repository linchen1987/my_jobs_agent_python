#!/usr/bin/env python3

import logging
from typing import List, Dict, Optional
from tools.fetch_page import fetch_json
from tools.parse_list import parse_eleduck_list
from tools.fetch_and_parse import fetch_and_parse_detail

# è·å–å½“å‰æ¨¡å—çš„logger
logger = logging.getLogger(__name__)

def fetch_and_parse_all(source_url_list: List[str], offset: int = 0, limit: Optional[int] = None) -> List[Dict]:
    """
    æŠ“å–æ‰€æœ‰è¯¦æƒ…é¡µæ•°æ®å¹¶è¿”å›ç»“æ„åŒ–æ•°æ®åˆ—è¡¨
    
    Args:
        source_url_list: æºURLåˆ—è¡¨
        offset: åç§»é‡ï¼Œä»ç¬¬å‡ ä¸ªå¼€å§‹è¿”å› (é»˜è®¤0)
        limit: é™åˆ¶æ•°é‡ï¼Œæœ€å¤šè¿”å›å¤šå°‘æ¡æ•°æ® (é»˜è®¤Noneï¼Œå³è¿”å›å…¨éƒ¨)
    
    Returns:
        List[Dict]: åŒ…å«è¯¦æƒ…é¡µæ•°æ®çš„åˆ—è¡¨ï¼Œæ ¹æ®offsetå’Œlimitå‚æ•°è¿‡æ»¤
    """
    logger.debug("=== å¼€å§‹æŠ“å–å’Œè§£æ eleduck æ•°æ® ===")
    
    all_posts = []
    
    # Step 1: æŠ“å–åˆ—è¡¨æ•°æ®
    logger.info("Step 1: æŠ“å–åˆ—è¡¨æ•°æ®...")
    for i, source_url in enumerate(source_url_list, 1):
        logger.debug(f"ğŸ“¥ æŠ“å–ç¬¬ {i} é¡µ: {source_url}")
        data = fetch_json(source_url)
        
        if data:
            posts = parse_eleduck_list(data)
            logger.debug(f"âœ… è§£æåˆ° {len(posts)} ä¸ªå¸–å­")
            all_posts.extend(posts)
        else:
            logger.error("âŒ æŠ“å–å¤±è´¥")
    
    logger.info(f"ğŸ“Š æ€»å…±è·å–åˆ° {len(all_posts)} ä¸ªå¸–å­")
    
    # Step 2: æ ¹æ®å‚æ•°è¿‡æ»¤å¸–å­åˆ—è¡¨
    total_posts = len(all_posts)
    
    if offset > 0 or (limit is not None and limit > 0):
        logger.info("Step 2: åº”ç”¨è¿‡æ»¤å‚æ•°...")
        logger.debug(f"   - ä»ç¬¬ {offset + 1} ä¸ªå¼€å§‹")
        if limit is not None:
            logger.debug(f"   - æœ€å¤šå¤„ç† {limit} æ¡")
        else:
            logger.debug("   - å¤„ç†å…¨éƒ¨å‰©ä½™æ•°æ®")
        
        # åº”ç”¨åˆ‡ç‰‡è¿‡æ»¤
        if limit is not None:
            filtered_posts = all_posts[offset:offset + limit]
        else:
            filtered_posts = all_posts[offset:]
        
        logger.info(f"   - è¿‡æ»¤ç»“æœ: å°†å¤„ç† {len(filtered_posts)}/{total_posts} ä¸ªå¸–å­")
    else:
        logger.info("Step 2: æ— è¿‡æ»¤å‚æ•°ï¼Œå¤„ç†å…¨éƒ¨å¸–å­")
        filtered_posts = all_posts
    
    # Step 3: æŠ“å–å¹¶è§£æè¿‡æ»¤åå¸–å­çš„è¯¦æƒ…é¡µ
    logger.info("Step 3: æŠ“å–è¯¦æƒ…é¡µæ•°æ®...")
    
    all_details = []
    success_count = 0
    
    for i, post in enumerate(filtered_posts, 1):
        post_id = post.get('id', '')
        post_url = post.get('url', '')
        post_title = post.get('title', 'Unknown')
        
        logger.debug(f"[{i}/{len(filtered_posts)}] å¤„ç†å¸–å­: {post_title}")
        logger.debug(f"ğŸ“ ID: {post_id}")
        logger.debug(f"ğŸ”— URL: {post_url}")
        
        if not post_url:
            logger.warning("âŒ è·³è¿‡: æ— æ•ˆçš„URL")
            continue
            
        # æŠ“å–è¯¦æƒ…é¡µæ•°æ®
        detail_data = fetch_and_parse_detail(post_url)
        
        if detail_data:
            # æ·»åŠ åˆ—è¡¨é¡µçš„å…ƒæ•°æ®åˆ°è¯¦æƒ…æ•°æ®ä¸­
            detail_data['list_metadata'] = post
            all_details.append(detail_data)
            success_count += 1
        else:
            logger.error("âŒ è¯¦æƒ…é¡µè§£æå¤±è´¥")
    
    logger.info(f"ğŸ“Š æˆåŠŸè·å– {success_count}/{len(filtered_posts)} ä¸ªè¯¦æƒ…é¡µæ•°æ®")
    logger.info(f"ğŸ“‹ è¿”å› {len(all_details)} æ¡è¯¦æƒ…æ•°æ®")
    
    return all_details 